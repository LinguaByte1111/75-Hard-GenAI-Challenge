{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2024-03-08T10:46:16.402794Z",
     "iopub.status.idle": "2024-03-08T10:46:16.403695Z",
     "shell.execute_reply": "2024-03-08T10:46:16.403417Z",
     "shell.execute_reply.started": "2024-03-08T10:46:16.403395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:12:49.501986Z",
     "iopub.status.busy": "2024-03-08T17:12:49.501506Z",
     "iopub.status.idle": "2024-03-08T17:13:03.644436Z",
     "shell.execute_reply": "2024-03-08T17:13:03.643341Z",
     "shell.execute_reply.started": "2024-03-08T17:12:49.501952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Wikipedia-API in c:\\python312\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from Wikipedia-API) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->Wikipedia-API) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->Wikipedia-API) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->Wikipedia-API) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->Wikipedia-API) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Wikipedia-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: transformers in c:\\\\python312\\\\lib\\\\site-packages (4.57.3)',\n",
       " 'Requirement already satisfied: filelock in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (3.18.0)',\n",
       " 'Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (0.34.3)',\n",
       " 'Requirement already satisfied: numpy>=1.17 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (2.1.3)',\n",
       " 'Requirement already satisfied: packaging>=20.0 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (24.2)',\n",
       " 'Requirement already satisfied: pyyaml>=5.1 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (6.0.2)',\n",
       " 'Requirement already satisfied: regex!=2019.12.17 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (2025.7.34)',\n",
       " 'Requirement already satisfied: requests in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (2.32.4)',\n",
       " 'Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (0.22.1)',\n",
       " 'Requirement already satisfied: safetensors>=0.4.3 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (0.5.3)',\n",
       " 'Requirement already satisfied: tqdm>=4.27 in c:\\\\python312\\\\lib\\\\site-packages (from transformers) (4.67.1)',\n",
       " 'Requirement already satisfied: fsspec>=2023.5.0 in c:\\\\python312\\\\lib\\\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)',\n",
       " 'Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\\\python312\\\\lib\\\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)',\n",
       " 'Requirement already satisfied: colorama in c:\\\\python312\\\\lib\\\\site-packages (from tqdm>=4.27->transformers) (0.4.6)',\n",
       " 'Requirement already satisfied: charset_normalizer<4,>=2 in c:\\\\python312\\\\lib\\\\site-packages (from requests->transformers) (3.4.2)',\n",
       " 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\python312\\\\lib\\\\site-packages (from requests->transformers) (2.10)',\n",
       " 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\python312\\\\lib\\\\site-packages (from requests->transformers) (2.4.0)',\n",
       " 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\python312\\\\lib\\\\site-packages (from requests->transformers) (2025.4.26)',\n",
       " '',\n",
       " '[notice] A new release of pip is available: 25.2 -> 25.3',\n",
       " '[notice] To update, run: python.exe -m pip install --upgrade pip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:13:03.647307Z",
     "iopub.status.busy": "2024-03-08T17:13:03.646905Z",
     "iopub.status.idle": "2024-03-08T17:13:04.395035Z",
     "shell.execute_reply": "2024-03-08T17:13:04.394266Z",
     "shell.execute_reply.started": "2024-03-08T17:13:03.647267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia('FreeBirds Crew (freebirdscrew@gmail.com)','en')\n",
    "\n",
    "def get_wikipedia_page(title):\n",
    "    page_py = wiki_wiki.page(title)\n",
    "    if not page_py.exists():\n",
    "        return None\n",
    "    return page_py.text\n",
    "\n",
    "page_title = \"Python (programming language)\"\n",
    "wikipedia_data = get_wikipedia_page(page_title)\n",
    "\n",
    "with open(\"wikipedia_data.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(wikipedia_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T10:57:22.682900Z",
     "iopub.status.busy": "2024-03-08T10:57:22.682476Z",
     "iopub.status.idle": "2024-03-08T10:57:27.190042Z",
     "shell.execute_reply": "2024-03-08T10:57:27.189246Z",
     "shell.execute_reply.started": "2024-03-08T10:57:22.682868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ade01ebf73f4988a38b2b4f9f0af8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dell\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeac7b6d4f943e58bb443bec5c95c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f146ce82ace34aa1ad5ed8f122df1ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3ef8c152844158a564ad12901967cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ba5471a5d74087880be826cedfbd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b23b6d44f44b3fa5702085eafc67ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74302ba07dd54df0884736aa233f507f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T10:57:33.732267Z",
     "iopub.status.busy": "2024-03-08T10:57:33.731535Z",
     "iopub.status.idle": "2024-03-08T10:57:34.011528Z",
     "shell.execute_reply": "2024-03-08T10:57:34.010702Z",
     "shell.execute_reply.started": "2024-03-08T10:57:33.732236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for fine-tuning\n",
    "train_data = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"wikipedia_data.txt\",\n",
    "    block_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T10:57:52.547504Z",
     "iopub.status.busy": "2024-03-08T10:57:52.547121Z",
     "iopub.status.idle": "2024-03-08T10:57:52.554048Z",
     "shell.execute_reply": "2024-03-08T10:57:52.552959Z",
     "shell.execute_reply.started": "2024-03-08T10:57:52.547477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       "), mlm=False, whole_word_mask=False, mlm_probability=0.15, mask_replace_prob=0.8, random_replace_prob=0.1, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt', seed=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T10:58:06.672640Z",
     "iopub.status.busy": "2024-03-08T10:58:06.671813Z",
     "iopub.status.idle": "2024-03-08T10:58:07.983596Z",
     "shell.execute_reply": "2024-03-08T10:58:07.982749Z",
     "shell.execute_reply.started": "2024-03-08T10:58:06.672607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine-tuned_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T10:58:17.331914Z",
     "iopub.status.busy": "2024-03-08T10:58:17.331179Z",
     "iopub.status.idle": "2024-03-08T10:59:20.128031Z",
     "shell.execute_reply": "2024-03-08T10:59:20.127020Z",
     "shell.execute_reply.started": "2024-03-08T10:58:17.331883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 13:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51, training_loss=3.272614422966452, metrics={'train_runtime': 832.8659, 'train_samples_per_second': 0.234, 'train_steps_per_second': 0.061, 'total_flos': 12737986560000.0, 'train_loss': 3.272614422966452, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:02:01.612850Z",
     "iopub.status.busy": "2024-03-08T11:02:01.612466Z",
     "iopub.status.idle": "2024-03-08T11:02:02.660276Z",
     "shell.execute_reply": "2024-03-08T11:02:02.659236Z",
     "shell.execute_reply.started": "2024-03-08T11:02:01.612822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine-tuned_model_gpt2_wiki_token\\\\tokenizer_config.json',\n",
       " './fine-tuned_model_gpt2_wiki_token\\\\special_tokens_map.json',\n",
       " './fine-tuned_model_gpt2_wiki_token\\\\vocab.json',\n",
       " './fine-tuned_model_gpt2_wiki_token\\\\merges.txt',\n",
       " './fine-tuned_model_gpt2_wiki_token\\\\added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./fine-tuned_model_gpt2_wiki\")\n",
    "\n",
    "tokenizer.save_pretrained(\"./fine-tuned_model_gpt2_wiki_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:02:29.480594Z",
     "iopub.status.busy": "2024-03-08T11:02:29.479724Z",
     "iopub.status.idle": "2024-03-08T11:02:34.937666Z",
     "shell.execute_reply": "2024-03-08T11:02:34.936671Z",
     "shell.execute_reply.started": "2024-03-08T11:02:29.480553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is GenAI?\n",
      "\n",
      "GenAI was developed by the World Wide Web Consortium (WWW), along with the Internet Archive (IA), which maintains and compiles the HTTP/2 protocol. GenAI is a Python-based programming language, which is part of the Python community. It supports a range of development platforms including Python, Ruby, and C.\n",
      "\n",
      "GenAI was developed as a way to support research in the field of artificial intelligence. It is currently the most widely used programming language, with more than 3 billion users.\n",
      "\n",
      "Why is GenAI relevant to programming?\n",
      "\n",
      "GenAI is a reflection of the programming philosophy of the Python community (including the current Python 3.8 and Python 3.7), which emphasizes greater abstraction, modularity, and modularity over traditional programming languages.\n",
      "\n",
      "GenAI is a general purpose language that can be used for many different tasks, including machine learning (ML), machine learning (ML-R), and machine learning and machine learning applications.\n",
      "\n",
      "How can I use GenAI to learn Python?\n",
      "\n",
      "In order to use GenAI as a learning tool, it has to be written in Python 2.7 or later.\n",
      "\n",
      "Python's syntax is defined in a module called Python. This module defines a set of Python\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fine_tuned_model = GPT2LMHeadModel.from_pretrained(\"./fine-tuned_model_gpt2_wiki\")\n",
    "fine_tuned_tokenizer = GPT2Tokenizer.from_pretrained(\"./fine-tuned_model_gpt2_wiki_token\")\n",
    "\n",
    "generator = pipeline('text-generation', model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)\n",
    "generated_text = generator(\"What is GenAI?\", max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
